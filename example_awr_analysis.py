#!/usr/bin/env python3
"""
AWR íŒŒì¼ ë¶„ì„ ì˜ˆì œ

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¨ì¼ AWR íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ë§ˆì´ê·¸ë ˆì´ì…˜ ë‚œì´ë„ë¥¼ í‰ê°€í•˜ê³ 
ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    python example_awr_analysis.py
"""

import os
from datetime import datetime

from src.dbcsi.parser import StatspackParser
from src.dbcsi.migration_analyzer import MigrationAnalyzer
from src.dbcsi.result_formatter import StatspackResultFormatter
from src.dbcsi.data_models import TargetDatabase


def main():
    """AWR íŒŒì¼ ë¶„ì„ ì˜ˆì œ"""
    
    # 1. AWR íŒŒì¼ ê²½ë¡œ ì„¤ì •
    awr_file = "sample_code/dbcsi_awr_sample01.out"
    
    if not os.path.exists(awr_file):
        print(f"âŒ AWR íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {awr_file}")
        return
    
    print("=" * 80)
    print("ğŸ“Š AWR íŒŒì¼ ë¶„ì„ ì˜ˆì œ")
    print("=" * 80)
    print(f"\në¶„ì„ íŒŒì¼: {awr_file}\n")
    
    # 2. AWR íŒŒì¼ íŒŒì‹±
    print("ğŸ” AWR íŒŒì¼ íŒŒì‹± ì¤‘...")
    parser = StatspackParser(awr_file)
    awr_data = parser.parse()
    print("âœ… íŒŒì‹± ì™„ë£Œ\n")
    
    # 3. ê¸°ë³¸ ì •ë³´ ì¶œë ¥
    print("=" * 80)
    print("ğŸ“‹ ì‹œìŠ¤í…œ ì •ë³´")
    print("=" * 80)
    print(f"ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„: {awr_data.os_info.db_name}")
    print(f"Oracle ë²„ì „: {awr_data.os_info.version}")
    print(f"Oracle ì—ë””ì…˜: {awr_data.os_info.banner}")
    print(f"í”Œë«í¼: {awr_data.os_info.platform_name}")
    print(f"CPU ì½”ì–´ ìˆ˜: {awr_data.os_info.num_cpu_cores}")
    print(f"ë¬¼ë¦¬ ë©”ëª¨ë¦¬: {awr_data.os_info.physical_memory_gb:.2f} GB")
    print(f"ë°ì´í„°ë² ì´ìŠ¤ í¬ê¸°: {awr_data.os_info.total_db_size_gb:.2f} GB")
    print(f"ì¸ìŠ¤í„´ìŠ¤ ìˆ˜: {awr_data.os_info.instances}")
    print(f"ìºë¦­í„°ì…‹: {awr_data.os_info.character_set}")
    print()
    
    # 4. AWR íŠ¹í™” ë°ì´í„° í™•ì¸
    print("=" * 80)
    print("ğŸ”¬ AWR íŠ¹í™” ë°ì´í„°")
    print("=" * 80)
    
    # ë°±ë¶„ìœ„ìˆ˜ CPU ë©”íŠ¸ë¦­
    if hasattr(awr_data, 'percentile_cpu') and awr_data.percentile_cpu:
        print("\nğŸ“Š CPU ë°±ë¶„ìœ„ìˆ˜ ë©”íŠ¸ë¦­:")
        for metric_name, metric_data in awr_data.percentile_cpu.items():
            print(f"  - {metric_name}: {metric_data.on_cpu} cores")
    else:
        print("\nâš ï¸  CPU ë°±ë¶„ìœ„ìˆ˜ ë°ì´í„° ì—†ìŒ (AWR íŒŒì„œ ë¯¸êµ¬í˜„)")
    
    # ë°±ë¶„ìœ„ìˆ˜ I/O ë©”íŠ¸ë¦­
    if hasattr(awr_data, 'percentile_io') and awr_data.percentile_io:
        print("\nğŸ“Š I/O ë°±ë¶„ìœ„ìˆ˜ ë©”íŠ¸ë¦­:")
        for metric_name, metric_data in awr_data.percentile_io.items():
            print(f"  - {metric_name}: {metric_data.rw_iops} IOPS, {metric_data.rw_mbps} MB/s")
    else:
        print("\nâš ï¸  I/O ë°±ë¶„ìœ„ìˆ˜ ë°ì´í„° ì—†ìŒ (AWR íŒŒì„œ ë¯¸êµ¬í˜„)")
    
    # ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼
    if hasattr(awr_data, 'workload_profiles') and awr_data.workload_profiles:
        print(f"\nğŸ“Š ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼: {len(awr_data.workload_profiles)}ê°œ ë ˆì½”ë“œ")
        print("  ìƒìœ„ 5ê°œ ì´ë²¤íŠ¸:")
        for profile in awr_data.workload_profiles[:5]:
            print(f"    - {profile.event} ({profile.module}): {profile.aas_contribution_pct:.2f}%")
    else:
        print("\nâš ï¸  ì›Œí¬ë¡œë“œ í”„ë¡œíŒŒì¼ ë°ì´í„° ì—†ìŒ (AWR íŒŒì„œ ë¯¸êµ¬í˜„)")
    
    # ë²„í¼ ìºì‹œ í†µê³„
    if hasattr(awr_data, 'buffer_cache_stats') and awr_data.buffer_cache_stats:
        print(f"\nğŸ“Š ë²„í¼ ìºì‹œ í†µê³„: {len(awr_data.buffer_cache_stats)}ê°œ ìŠ¤ëƒ…ìƒ·")
        avg_hit_ratio = sum(s.hit_ratio for s in awr_data.buffer_cache_stats) / len(awr_data.buffer_cache_stats)
        print(f"  í‰ê·  íˆíŠ¸ìœ¨: {avg_hit_ratio:.2f}%")
    else:
        print("\nâš ï¸  ë²„í¼ ìºì‹œ ë°ì´í„° ì—†ìŒ (AWR íŒŒì„œ ë¯¸êµ¬í˜„)")
    
    # I/O í•¨ìˆ˜ë³„ í†µê³„
    if hasattr(awr_data, 'iostat_functions') and awr_data.iostat_functions:
        print(f"\nğŸ“Š I/O í•¨ìˆ˜ë³„ í†µê³„: {len(awr_data.iostat_functions)}ê°œ ë ˆì½”ë“œ")
        io_by_function = {}
        for iostat in awr_data.iostat_functions:
            if iostat.function_name not in io_by_function:
                io_by_function[iostat.function_name] = []
            io_by_function[iostat.function_name].append(iostat.megabytes_per_s)
        
        for func, values in io_by_function.items():
            avg_io = sum(values) / len(values)
            print(f"  - {func}: {avg_io:.2f} MB/s (í‰ê· )")
    else:
        print("\nâš ï¸  I/O í•¨ìˆ˜ë³„ ë°ì´í„° ì—†ìŒ (AWR íŒŒì„œ ë¯¸êµ¬í˜„)")
    
    print()
    
    # 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ë¶„ì„
    print("=" * 80)
    print("ğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ë‚œì´ë„ ë¶„ì„")
    print("=" * 80)
    print("\në¶„ì„ ì¤‘...\n")
    
    analyzer = MigrationAnalyzer(awr_data)
    analysis_results = analyzer.analyze()
    
    # ê° íƒ€ê²Ÿë³„ ê²°ê³¼ ì¶œë ¥
    for target, complexity in analysis_results.items():
        print(f"\n### {target.value}")
        print(f"ë‚œì´ë„ ì ìˆ˜: {complexity.score:.2f} / 10.0")
        print(f"ë‚œì´ë„ ë ˆë²¨: {complexity.level}")
        
        # ì¸ìŠ¤í„´ìŠ¤ ì¶”ì²œ (RDS Oracleë§Œ)
        if complexity.instance_recommendation:
            rec = complexity.instance_recommendation
            print(f"\nì¶”ì²œ ì¸ìŠ¤í„´ìŠ¤:")
            print(f"  - íƒ€ì…: {rec.instance_type}")
            print(f"  - vCPU: {rec.vcpu}")
            print(f"  - ë©”ëª¨ë¦¬: {rec.memory_gib} GiB")
            print(f"  - CPU ì—¬ìœ ë¶„: {rec.cpu_headroom_pct:.1f}%")
            print(f"  - ë©”ëª¨ë¦¬ ì—¬ìœ ë¶„: {rec.memory_headroom_pct:.1f}%")
        
        print(f"\nì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        for i, rec in enumerate(complexity.recommendations[:3], 1):
            print(f"  {i}. {rec}")
    
    print()
    
    # 6. ë¦¬í¬íŠ¸ ì €ì¥
    print("=" * 80)
    print("ğŸ’¾ ë¦¬í¬íŠ¸ ì €ì¥")
    print("=" * 80)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "reports"
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # JSON ì €ì¥
    json_output = StatspackResultFormatter.to_json(awr_data)
    json_path = os.path.join(output_dir, f"awr_analysis_{timestamp}.json")
    with open(json_path, "w", encoding="utf-8") as f:
        f.write(json_output)
    print(f"âœ… JSON ë¦¬í¬íŠ¸ ì €ì¥: {json_path}")
    
    # Markdown ì €ì¥
    markdown_output = StatspackResultFormatter.to_markdown(awr_data, analysis_results)
    markdown_path = os.path.join(output_dir, f"awr_analysis_{timestamp}.md")
    with open(markdown_path, "w", encoding="utf-8") as f:
        f.write(markdown_output)
    print(f"âœ… Markdown ë¦¬í¬íŠ¸ ì €ì¥: {markdown_path}")
    
    print()
    print("=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)


if __name__ == "__main__":
    main()
