#!/usr/bin/env python3
"""sample_plsql01~04 íŒŒì¼ë“¤ì„ ë³‘ë ¬ë¡œ ë¶„ì„í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸"""

from src.oracle_complexity_analyzer import (
    OracleComplexityAnalyzer,
    TargetDatabase,
    BatchAnalyzer
)
from pathlib import Path
import concurrent.futures

def analyze_files_parallel(analyzer, file_paths, max_workers=4):
    """íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³‘ë ¬ë¡œ ë¶„ì„"""
    results = []
    errors = []
    
    def analyze_single(file_path):
        try:
            result = analyzer.analyze_file(str(file_path))
            return (str(file_path), result, None)
        except Exception as e:
            return (str(file_path), None, str(e))
    
    # ThreadPoolExecutor ì‚¬ìš© (Pickle ë¬¸ì œ íšŒí”¼)
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(analyze_single, fp) for fp in file_paths]
        
        for future in concurrent.futures.as_completed(futures):
            file_path, result, error = future.result()
            if error:
                errors.append((file_path, error))
            else:
                results.append((file_path, result))
    
    return results, errors

def calculate_stats(results):
    """ë¶„ì„ ê²°ê³¼ í†µê³„ ê³„ì‚°"""
    if not results:
        return {
            'total': 0,
            'success': 0,
            'average_score': 0.0,
            'distribution': {},
            'top_files': []
        }
    
    scores = [(fp, r.normalized_score) for fp, r in results]
    levels = {}
    
    for fp, r in results:
        level = r.complexity_level.value
        levels[level] = levels.get(level, 0) + 1
    
    avg_score = sum(s for _, s in scores) / len(scores)
    top_files = sorted(scores, key=lambda x: x[1], reverse=True)
    
    return {
        'total': len(results),
        'success': len(results),
        'average_score': avg_score,
        'distribution': levels,
        'top_files': top_files
    }

def main():
    print("=" * 80)
    print("sample_plsql01~04 ë°°ì¹˜ ë¶„ì„ (ë³‘ë ¬ ì²˜ë¦¬)")
    print("=" * 80)
    print()
    
    # ë¶„ì„ ëŒ€ìƒ íŒŒì¼ ì°¾ê¸°
    sample_files = sorted(Path("sample_code").glob("sample_plsql*.sql"))
    print(f"ë¶„ì„ ëŒ€ìƒ íŒŒì¼: {len(sample_files)}ê°œ")
    for f in sample_files:
        print(f"  - {f}")
    print()
    
    # PostgreSQL íƒ€ê²Ÿ ë¶„ì„
    print("1. PostgreSQL íƒ€ê²Ÿìœ¼ë¡œ ë°°ì¹˜ ë¶„ì„")
    print("-" * 80)
    
    analyzer_pg = OracleComplexityAnalyzer(
        target_database=TargetDatabase.POSTGRESQL,
        output_dir="batch_analysis_results"
    )
    
    print("ë¶„ì„ ì¤‘...")
    results_pg, errors_pg = analyze_files_parallel(analyzer_pg, sample_files, max_workers=4)
    
    print()
    print("ë¶„ì„ ì™„ë£Œ!")
    print()
    
    stats_pg = calculate_stats(results_pg)
    
    print("ğŸ“Š ìš”ì•½ í†µê³„ (PostgreSQL)")
    print(f"  - ì „ì²´ íŒŒì¼ ìˆ˜: {len(sample_files)}")
    print(f"  - ë¶„ì„ ì„±ê³µ: {stats_pg['success']}")
    print(f"  - ë¶„ì„ ì‹¤íŒ¨: {len(errors_pg)}")
    print(f"  - í‰ê·  ë³µì¡ë„ ì ìˆ˜: {stats_pg['average_score']:.2f} / 10")
    print()
    
    if errors_pg:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨ íŒŒì¼:")
        for fp, err in errors_pg:
            print(f"  - {Path(fp).name}: {err}")
        print()
    
    print("ğŸ“ˆ ë³µì¡ë„ ë ˆë²¨ë³„ ë¶„í¬:")
    for level, count in stats_pg['distribution'].items():
        percentage = (count / stats_pg['total'] * 100) if stats_pg['total'] > 0 else 0
        print(f"  - {level}: {count}ê°œ ({percentage:.1f}%)")
    print()
    
    print("ğŸ”¥ ë³µì¡ë„ ë†’ì€ íŒŒì¼:")
    for idx, (file_path, score) in enumerate(stats_pg['top_files'], 1):
        print(f"  {idx}. {Path(file_path).name}: {score:.2f}")
    print()
    
    # ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥
    for file_path, result in results_pg:
        file_name = Path(file_path).stem
        analyzer_pg.export_json(result, f"{file_name}_pg.json")
        analyzer_pg.export_markdown(result, f"{file_name}_pg.md")
    
    print(f"PostgreSQL ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print()
    
    # MySQL íƒ€ê²Ÿ ë¶„ì„
    print("=" * 80)
    print("2. MySQL íƒ€ê²Ÿìœ¼ë¡œ ë°°ì¹˜ ë¶„ì„")
    print("-" * 80)
    
    analyzer_mysql = OracleComplexityAnalyzer(
        target_database=TargetDatabase.MYSQL,
        output_dir="batch_analysis_results"
    )
    
    print("ë¶„ì„ ì¤‘...")
    results_mysql, errors_mysql = analyze_files_parallel(analyzer_mysql, sample_files, max_workers=4)
    
    print()
    print("ë¶„ì„ ì™„ë£Œ!")
    print()
    
    stats_mysql = calculate_stats(results_mysql)
    
    print("ğŸ“Š ìš”ì•½ í†µê³„ (MySQL)")
    print(f"  - ì „ì²´ íŒŒì¼ ìˆ˜: {len(sample_files)}")
    print(f"  - ë¶„ì„ ì„±ê³µ: {stats_mysql['success']}")
    print(f"  - ë¶„ì„ ì‹¤íŒ¨: {len(errors_mysql)}")
    print(f"  - í‰ê·  ë³µì¡ë„ ì ìˆ˜: {stats_mysql['average_score']:.2f} / 10")
    print()
    
    if errors_mysql:
        print("âŒ ë¶„ì„ ì‹¤íŒ¨ íŒŒì¼:")
        for fp, err in errors_mysql:
            print(f"  - {Path(fp).name}: {err}")
        print()
    
    print("ğŸ“ˆ ë³µì¡ë„ ë ˆë²¨ë³„ ë¶„í¬:")
    for level, count in stats_mysql['distribution'].items():
        percentage = (count / stats_mysql['total'] * 100) if stats_mysql['total'] > 0 else 0
        print(f"  - {level}: {count}ê°œ ({percentage:.1f}%)")
    print()
    
    print("ğŸ”¥ ë³µì¡ë„ ë†’ì€ íŒŒì¼:")
    for idx, (file_path, score) in enumerate(stats_mysql['top_files'], 1):
        print(f"  {idx}. {Path(file_path).name}: {score:.2f}")
    print()
    
    # ê°œë³„ íŒŒì¼ ê²°ê³¼ ì €ì¥
    for file_path, result in results_mysql:
        file_name = Path(file_path).stem
        analyzer_mysql.export_json(result, f"{file_name}_mysql.json")
        analyzer_mysql.export_markdown(result, f"{file_name}_mysql.md")
    
    print(f"MySQL ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ")
    print()
    
    # ë¹„êµ ë¶„ì„
    print("=" * 80)
    print("3. PostgreSQL vs MySQL ë¹„êµ")
    print("-" * 80)
    print(f"í‰ê·  ë³µì¡ë„ ì ìˆ˜:")
    print(f"  - PostgreSQL: {stats_pg['average_score']:.2f}")
    print(f"  - MySQL: {stats_mysql['average_score']:.2f}")
    print(f"  - ì°¨ì´: {stats_mysql['average_score'] - stats_pg['average_score']:.2f}")
    print()
    
    print("íŒŒì¼ë³„ ë³µì¡ë„ ë¹„êµ:")
    for (fp_pg, result_pg), (fp_mysql, result_mysql) in zip(results_pg, results_mysql):
        file_name = Path(fp_pg).name
        diff = result_mysql.normalized_score - result_pg.normalized_score
        print(f"  - {file_name}:")
        print(f"      PostgreSQL: {result_pg.normalized_score:.2f}, MySQL: {result_mysql.normalized_score:.2f}, ì°¨ì´: {diff:+.2f}")
    print()
    
    print("=" * 80)
    print("ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ!")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: batch_analysis_results/20260114/")
    print("=" * 80)

if __name__ == "__main__":
    main()
