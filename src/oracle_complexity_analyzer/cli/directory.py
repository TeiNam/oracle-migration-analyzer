"""
í´ë” ë¶„ì„

í´ë” ë‚´ SQL/PL-SQL íŒŒì¼ë“¤ì„ ì¼ê´„ ë¶„ì„í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
from typing import Any

from ..enums import TargetDatabase
from ..analyzer import OracleComplexityAnalyzer
from ..batch_analyzer import BatchAnalyzer
from .utils import normalize_target, is_all_targets
from .console_output import print_batch_result_console, print_batch_analysis_summary

logger = logging.getLogger(__name__)


def analyze_directory(args: Any) -> int:
    """í´ë” ì¼ê´„ ë¶„ì„ ì‹¤í–‰
    
    Args:
        args: ëª…ë ¹ì¤„ ì¸ì
        
    Returns:
        int: ì¢…ë£Œ ì½”ë“œ (0: ì„±ê³µ, 1: ì‹¤íŒ¨)
    """
    try:
        # all/both ì˜µì…˜ì¸ ê²½ìš° ë‘ íƒ€ê²Ÿ ëª¨ë‘ ë¶„ì„
        if is_all_targets(args.target):
            return analyze_directory_all_targets(args)
        
        target_db = normalize_target(args.target)
        
        analyzer = OracleComplexityAnalyzer(
            target_database=target_db,
            output_dir=args.output_dir
        )
        
        batch_analyzer = BatchAnalyzer(analyzer, max_workers=args.workers)
        
        print(f"ğŸ“ í´ë” ê²€ìƒ‰ ì¤‘: {args.directory}")
        sql_files = batch_analyzer.find_sql_files(args.directory)
        print(f"âœ… {len(sql_files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        if not sql_files:
            print("âš ï¸  ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        print(f"\nğŸ”„ ë¶„ì„ ì‹œì‘ (ì›Œì»¤ ìˆ˜: {batch_analyzer.max_workers})")
        
        batch_result = _run_batch_analysis(batch_analyzer, args)
        
        _output_batch_results(batch_result, target_db, args)
        _export_batch_reports(batch_analyzer, batch_result, args)
        
        return 0
        
    except FileNotFoundError as e:
        logger.error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        return 1
    except ValueError as e:
        logger.error(f"ì˜ëª»ëœ ê°’: {e}")
        return 1
    except Exception as e:
        logger.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}", exc_info=True)
        return 1


def analyze_directory_all_targets(args: Any) -> int:
    """í´ë” ì¼ê´„ ë¶„ì„ - ëª¨ë“  íƒ€ê²Ÿ (PostgreSQL + MySQL)
    
    Args:
        args: ëª…ë ¹ì¤„ ì¸ì
        
    Returns:
        int: ì¢…ë£Œ ì½”ë“œ (0: ì„±ê³µ, 1: ì‹¤íŒ¨)
    """
    targets = [TargetDatabase.POSTGRESQL, TargetDatabase.MYSQL]
    
    print(f"ğŸ“ í´ë” ê²€ìƒ‰ ì¤‘: {args.directory}")
    
    for target_db in targets:
        print(f"\n{'='*60}")
        print(f"ğŸ¯ íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤: {target_db.value}")
        print(f"{'='*60}")
        
        try:
            analyzer = OracleComplexityAnalyzer(
                target_database=target_db,
                output_dir=args.output_dir
            )
            
            batch_analyzer = BatchAnalyzer(analyzer, max_workers=args.workers)
            
            sql_files = batch_analyzer.find_sql_files(args.directory)
            
            if not sql_files:
                print("âš ï¸  ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            print(f"âœ… {len(sql_files)}ê°œ íŒŒì¼ ë°œê²¬")
            print(f"ğŸ”„ ë¶„ì„ ì‹œì‘ (ì›Œì»¤ ìˆ˜: {batch_analyzer.max_workers})")
            
            batch_result = _run_batch_analysis(batch_analyzer, args)
            
            _output_batch_results(batch_result, target_db, args)
            _export_batch_reports(batch_analyzer, batch_result, args)
                
        except Exception as e:
            logger.error(f"{target_db.value} ë¶„ì„ ì‹¤íŒ¨: {e}", exc_info=True)
            continue
    
    print(f"\n{'='*60}")
    print("âœ… ëª¨ë“  íƒ€ê²Ÿ ë¶„ì„ ì™„ë£Œ")
    print(f"{'='*60}")
    
    return 0


def _run_batch_analysis(batch_analyzer: BatchAnalyzer, args: Any) -> Any:
    """ë°°ì¹˜ ë¶„ì„ ì‹¤í–‰"""
    if not args.no_progress:
        try:
            from tqdm import tqdm
            return batch_analyzer.analyze_folder_with_progress(
                args.directory,
                progress_callback=lambda current, total: None
            )
        except ImportError:
            print("ì§„í–‰ ì¤‘...", end='', flush=True)
            result = batch_analyzer.analyze_folder(args.directory)
            print(" ì™„ë£Œ!")
            return result
    else:
        return batch_analyzer.analyze_folder(args.directory)


def _output_batch_results(batch_result: Any, target_db: TargetDatabase, args: Any) -> None:
    """ë°°ì¹˜ ê²°ê³¼ ì½˜ì†” ì¶œë ¥"""
    if args.output in ['console', 'both']:
        if hasattr(batch_result, 'total_files'):
            print_batch_analysis_summary(batch_result, target_db)
        else:
            print_batch_result_console(batch_result, target_db)


def _export_batch_reports(batch_analyzer: BatchAnalyzer, batch_result: Any, args: Any) -> None:
    """ë°°ì¹˜ ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸°"""
    if args.output in ['json', 'both']:
        json_path = batch_analyzer.export_batch_json(
            batch_result,
            include_details=args.details
        )
        print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {json_path}")
    
    if args.output in ['markdown', 'both']:
        md_path = batch_analyzer.export_batch_markdown(
            batch_result,
            include_details=args.details
        )
        print(f"âœ… Markdown ì €ì¥ ì™„ë£Œ: {md_path}")
    
    if args.output in ['markdown', 'both']:
        print(f"\nğŸ“ ê°œë³„ íŒŒì¼ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        individual_files = batch_analyzer.export_individual_reports(batch_result)
        print(f"âœ… {len(individual_files)}ê°œ ê°œë³„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
