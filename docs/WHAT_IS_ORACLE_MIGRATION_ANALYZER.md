# Oracle Migration Analyzer란 무엇인가?

> Oracle 데이터베이스를 AWS 클라우드로 옮길 때, "얼마나 어려울까?"를 자동으로 분석해주는 똑똑한 도구입니다.

## 🎯 한 문장 정의

**Oracle Migration Analyzer는 Oracle 데이터베이스의 코드와 성능 데이터를 분석하여, AWS 클라우드로의 마이그레이션 난이도를 0-10점으로 점수화하고, 가장 적합한 이관 전략(Replatform, Refactor to MySQL, Refactor to PostgreSQL)을 자동으로 추천해주는 Python 기반 분석 도구입니다.**

---

## 🤔 왜 필요한가?

### 문제 상황

Oracle 데이터베이스를 AWS로 옮기려고 할 때 이런 고민들이 생깁니다:

1. **"우리 코드가 얼마나 복잡한가?"**
   - SQL 쿼리 수천 개, PL/SQL 프로시저 수백 개... 일일이 확인할 수 없음
   - 어떤 코드가 문제가 될지 모름

2. **"어떤 전략이 최선인가?"**
   - RDS for Oracle로 그냥 옮길까? (Replatform)
   - Aurora MySQL로 바꿀까? (Refactor)
   - Aurora PostgreSQL로 바꿀까? (Refactor)

3. **"비용과 시간이 얼마나 들까?"**
   - 견적을 내려면 코드를 분석해야 하는데 시간이 너무 오래 걸림
   - 잘못 판단하면 프로젝트가 실패할 수도 있음

4. **"어떤 위험이 있을까?"**
   - 성능 문제는 없을까?
   - 호환되지 않는 기능은 없을까?


### 해결책

Oracle Migration Analyzer는 이 모든 질문에 **자동으로** 답을 제공합니다:

✅ **코드 복잡도를 숫자로 보여줌** (0-10점)
✅ **최적의 전략을 추천** (3가지 중 선택)
✅ **예상 기간과 비용 제시** (단계별 로드맵)
✅ **위험 요소와 해결 방법 제공**

---

## 🔍 무엇을 분석하나?

Oracle Migration Analyzer는 **3가지 핵심 영역**을 분석합니다:

### 1. 코드 복잡도 분석 (SQL/PL-SQL Analyzer)

**분석 대상**: SQL 쿼리, PL/SQL 프로시저, 함수, 패키지, 트리거 등

**분석 내용**:
- JOIN이 몇 개나 있나?
- 서브쿼리가 얼마나 깊게 중첩되어 있나?
- Oracle 전용 기능(CONNECT BY, PIVOT 등)을 사용하나?
- 코드가 얼마나 긴가?
- 변환하기 어려운 기능이 있나?

**결과**:
```
복잡도 점수: 6.5 / 10
복잡도 레벨: 복잡 (High effort)
권장사항: 상당한 재작성 필요
```

**예시**:
- 단순한 SELECT 쿼리 → 1.2점 (매우 간단)
- CONNECT BY를 사용한 계층 쿼리 → 7.8점 (매우 복잡)
- 500줄짜리 패키지 → 8.5점 (매우 복잡)



### 2. 성능 메트릭 분석 (DBCSI Analyzer)

**분석 대상**: AWR 리포트 또는 Statspack 리포트

**분석 내용**:
- CPU를 얼마나 사용하나?
- 메모리는 얼마나 필요한가?
- I/O 부하는 어느 정도인가?
- 어떤 시간대에 부하가 높은가?
- 버퍼 캐시 효율은 좋은가?

**결과**:
```
평균 CPU 사용률: 45%
피크 CPU 사용률 (P99): 78%
평균 메모리: 32GB
권장 인스턴스: db.r6i.2xlarge (8 vCPU, 64GB)
```

**특별한 점**:
- **백분위수 기반 분석**: 평균이 아닌 P99(상위 1%) 기준으로 사이징
  - 평균만 보면 → 작은 인스턴스 선택 → 피크 시간에 성능 문제 발생
  - P99를 보면 → 적절한 인스턴스 선택 → 안정적인 성능 보장



### 3. 마이그레이션 전략 추천 (Migration Recommendation Engine)

**분석 대상**: 위 1번과 2번의 결과를 종합

**분석 내용**:
- 코드 복잡도와 개수를 2차원으로 평가
- 성능 요구사항 고려
- 비용 효율성 계산
- 위험 요소 식별

**결과**:
```
추천 전략: Aurora PostgreSQL로 Refactor
신뢰도: 높음
예상 기간: 16-20주
예상 비용: $850,000
```

**의사결정 로직**:

```
┌─────────────────────────────────────────────────────────┐
│  복잡도가 매우 높나? (PostgreSQL 5.0 이상 / MySQL 7.0 이상) │
│  또는 복잡한 코드가 30% 이상인가?                       │
└─────────────────────────────────────────────────────────┘
         │                                    │
        YES                                  NO
         │                                    │
         ▼                                    ▼
   ┌─────────┐                    ┌──────────────────────┐
   │Replatform│                    │ BULK 연산이 많나?    │
   │(RDS      │                    │ (10개 이상)          │
   │Oracle)   │                    └──────────────────────┘
   └─────────┘                              │          │
                                          YES         NO
                                           │          │
                                           ▼          ▼
                                    ┌──────────┐  ┌────────────┐
                                    │PostgreSQL│  │복잡도 낮고 │
                                    │          │  │개수 적나?  │
                                    └──────────┘  └────────────┘
                                                        │      │
                                                      YES     NO
                                                       │      │
                                                       ▼      ▼
                                                  ┌──────┐ ┌──────────┐
                                                  │MySQL │ │PostgreSQL│
                                                  └──────┘ └──────────┘
```



---

## 🎬 어떻게 작동하나?

### 간단한 3단계 프로세스

```bash
# 1단계: 코드 복잡도 분석 (5분)
oracle-complexity-analyzer -d /path/to/sql/files -o markdown

# 2단계: 성능 메트릭 분석 (2분)
dbcsi-analyzer --file awr_report.out --format markdown

# 3단계: 최종 추천 리포트 생성 (1분)
migration-recommend --reports-dir reports/
```

**총 소요 시간: 약 10분** (수동 분석 시 수주~수개월 소요)

### 상세 작동 원리

#### 1단계: 코드 복잡도 분석

```
입력: SQL/PL-SQL 파일들
  ↓
[파일 타입 감지]
  ↓
[SQL 파서] ──→ JOIN, 서브쿼리, CTE 등 분석
  ↓
[PL/SQL 파서] ──→ 커서, 예외, BULK 연산 등 분석
  ↓
[복잡도 계산기]
  ├─ 구조적 복잡성 (0-3점)
  ├─ Oracle 특화 기능 (0-3점)
  ├─ 함수/표현식 (0-2.5점)
  ├─ 데이터 볼륨 (0-2.5점)
  ├─ 실행 복잡성 (0-2.5점)
  └─ 변환 난이도 (0-4.5점)
  ↓
[점수 정규화] ──→ 0-10점으로 변환
  ↓
출력: 복잡도 리포트 (JSON/Markdown)
```

**핵심 알고리즘**:
- **가중치 기반 점수 계산**: PostgreSQL과 MySQL 각각 다른 가중치 적용
- **임계값 기반 분류**: 점수에 따라 6단계 레벨 분류
- **변환 가이드 자동 생성**: 감지된 Oracle 기능별 대체 방법 제시



#### 2단계: 성능 메트릭 분석

```
입력: AWR/Statspack 리포트 (.out 파일)
  ↓
[파일 타입 감지] ──→ AWR vs Statspack 구분
  ↓
[섹션별 파서]
  ├─ OS-INFO ──→ CPU, 메모리 정보
  ├─ MAIN-METRICS ──→ CPU 사용률, I/O 부하
  ├─ WAIT-EVENTS ──→ 대기 이벤트 분석
  ├─ FEATURES ──→ Oracle 기능 사용 현황
  └─ [AWR 전용]
      ├─ PERCENT-CPU ──→ P99, P95 백분위수
      ├─ PERCENT-IO ──→ IOPS, MBPS 백분위수
      ├─ WORKLOAD ──→ 시간대별 부하 패턴
      └─ BUFFER-CACHE ──→ 캐시 효율성
  ↓
[마이그레이션 분석기]
  ├─ 인스턴스 사이징 (P99 기준)
  ├─ 워크로드 패턴 분석
  ├─ 버퍼 캐시 최적화
  └─ I/O 병목 분석
  ↓
출력: 성능 분석 리포트 (JSON/Markdown)
```

**핵심 알고리즘**:
- **백분위수 기반 사이징**: 평균이 아닌 P99 기준으로 안정적인 성능 보장
- **워크로드 패턴 분류**: CPU 집약적 vs I/O 집약적 vs 혼합형
- **버퍼 캐시 최적화**: 히트율 분석 후 권장 크기 계산



#### 3단계: 마이그레이션 전략 추천

```
입력: 1단계 + 2단계 결과
  ↓
[결과 통합기]
  ├─ 평균 SQL 복잡도 계산
  ├─ 평균 PL/SQL 복잡도 계산
  ├─ 복잡한 코드 비율 계산
  ├─ BULK 연산 개수 집계
  ├─ 성능 메트릭 추출
  └─ PL/SQL 라인 수 추출
  ↓
[의사결정 엔진]
  ├─ 복잡도 × 개수 2차원 평가
  ├─ BULK 연산 고려
  ├─ 비용 효율성 계산
  └─ 전략 선택 (3가지 중 1개)
  ↓
[리포트 생성기]
  ├─ Executive Summary (경영진용)
  ├─ 추천 근거 (4가지 카테고리)
  ├─ 대안 전략 비교
  ├─ 위험 요소 및 완화 방안
  ├─ 마이그레이션 로드맵 (단계별)
  └─ 인스턴스 추천
  ↓
출력: 종합 추천 리포트 (JSON/Markdown)
```

**핵심 알고리즘**:
- **2차원 의사결정 매트릭스**: 복잡도와 개수를 동시에 고려
- **비용 효율성 계산**: 50,000줄 이상 + 복잡도 낮음 → Replatform이 더 저렴
- **AI 도구 통합**: 40% 시간 절감, 35% 비용 절감 반영



---

## 🎯 3가지 마이그레이션 전략

### 1. Replatform (RDS for Oracle SE2)

**한 줄 요약**: Oracle을 그대로 AWS로 옮기기

**언제 선택하나?**
- 코드가 너무 복잡해서 변환이 거의 불가능할 때
- 복잡한 코드가 30% 이상일 때
- 빠르게 클라우드로 옮겨야 할 때

**장점**:
- ✅ 코드 변경 최소화 (거의 그대로 사용)
- ✅ 빠른 마이그레이션 (8-12주)
- ✅ 높은 호환성 (99% 이상)
- ✅ 검증된 안정성

**단점**:
- ❌ Oracle 라이선스 비용 계속 지불
- ❌ Single 인스턴스만 지원 (RAC 미지원)
- ❌ 장기적으로 비용이 높음
- ❌ 클라우드 네이티브 기능 활용 제한

**예상 비용** (예시):
- 초기 마이그레이션: $200,000
- 연간 운영 비용: $120,000 (라이선스 포함)

**적합한 경우**:
```
✓ 평균 복잡도 >= 7.0
✓ 복잡한 코드 비율 >= 30%
✓ 코드 라인 수 >= 50,000줄 (복잡도 낮아도 비용 효율적)
✓ 빠른 마이그레이션이 최우선
```



### 2. Refactor to Aurora MySQL

**한 줄 요약**: MySQL로 바꾸고 PL/SQL은 애플리케이션으로 옮기기

**언제 선택하나?**
- 코드가 단순하고 개수가 적을 때
- PL/SQL을 애플리케이션 레벨로 옮길 수 있을 때
- 비용 절감이 최우선일 때

**장점**:
- ✅ 오픈소스 기반 (라이선스 비용 없음)
- ✅ 낮은 TCO (총 소유 비용)
- ✅ 단순한 SQL 처리에 최적
- ✅ 높은 성능 (읽기 작업)

**단점**:
- ❌ 모든 PL/SQL을 애플리케이션으로 이관 필요
- ❌ MySQL Stored Procedure 사용 불가 (권장하지 않음)
- ❌ BULK 연산 미지원
- ❌ 복잡한 트랜잭션 처리 제한

**예상 비용** (예시):
- 초기 마이그레이션: $600,000
- 연간 운영 비용: $40,000 (라이선스 비용 없음)

**적합한 경우**:
```
✓ 평균 SQL 복잡도 <= 5.0
✓ 평균 PL/SQL 복잡도 <= 5.0
✓ PL/SQL 오브젝트 < 50개
✓ BULK 연산 < 10개
✓ 장기적 비용 절감이 목표
```

**주의사항**:
- PL/SQL을 Java/Python 등 애플리케이션 코드로 재작성 필요
- 트랜잭션 로직을 애플리케이션에서 관리해야 함
- 초기 개발 비용은 높지만 장기적으로 저렴



### 3. Refactor to Aurora PostgreSQL

**한 줄 요약**: PostgreSQL로 바꾸고 PL/SQL을 PL/pgSQL로 변환하기

**언제 선택하나?**
- 코드가 중간 정도 복잡할 때
- PL/SQL을 데이터베이스에 유지하고 싶을 때
- BULK 연산이 많을 때

**장점**:
- ✅ PL/pgSQL이 Oracle PL/SQL과 70-75% 호환
- ✅ BULK 연산 대체 가능 (ARRAY 사용)
- ✅ 고급 기능 지원 (JSON, Full-text search 등)
- ✅ 오픈소스 기반 (라이선스 비용 없음)
- ✅ 활발한 커뮤니티

**단점**:
- ❌ PL/SQL 변환 작업 필요
- ❌ BULK 연산 성능 차이 (20-50% 느림)
- ❌ 일부 Oracle 기능 미지원 (CONNECT BY 등)
- ❌ 학습 곡선 존재

**예상 비용** (예시):
- 초기 마이그레이션: $850,000
- 연간 운영 비용: $50,000 (라이선스 비용 없음)

**적합한 경우**:
```
✓ 평균 복잡도 5.0-7.0 (중간)
✓ BULK 연산 >= 10개
✓ PL/SQL을 데이터베이스에 유지하고 싶음
✓ 균형 잡힌 접근 (비용 vs 기능)
```

**변환 예시**:

**Oracle PL/SQL**:
```sql
-- BULK COLLECT 사용
DECLARE
  TYPE emp_array IS TABLE OF employees%ROWTYPE;
  emp_list emp_array;
BEGIN
  SELECT * BULK COLLECT INTO emp_list
  FROM employees WHERE department_id = 10;
  
  FORALL i IN emp_list.FIRST..emp_list.LAST
    UPDATE employees SET salary = salary * 1.1
    WHERE employee_id = emp_list(i).employee_id;
END;
```

**PostgreSQL PL/pgSQL**:
```sql
-- ARRAY 사용으로 대체
DO $$
DECLARE
  emp_ids INTEGER[];
BEGIN
  SELECT ARRAY_AGG(employee_id) INTO emp_ids
  FROM employees WHERE department_id = 10;
  
  UPDATE employees SET salary = salary * 1.1
  WHERE employee_id = ANY(emp_ids);
END $$;
```



---

## 📊 실제 사용 예시

### 시나리오 1: 대형 금융사 (복잡도 높음)

**상황**:
- SQL 쿼리: 3,500개
- PL/SQL 오브젝트: 850개 (패키지 120개, 프로시저 450개, 함수 280개)
- 코드 라인 수: 125,000줄
- 평균 복잡도: 7.8 / 10

**분석 결과**:
```
복잡도 분포:
- 매우 복잡 (7-10점): 45%
- 복잡 (5-7점): 30%
- 중간 (3-5점): 20%
- 간단 (0-3점): 5%

감지된 Oracle 특화 기능:
- CONNECT BY 계층 쿼리: 85개
- BULK COLLECT: 120개
- 패키지 의존성: 350개
- DB Link: 25개
```

**추천 전략**: **Replatform (RDS for Oracle SE2)**

**근거**:
1. 복잡한 코드 비율이 45%로 매우 높음
2. CONNECT BY 같은 변환 어려운 기능 다수 사용
3. 패키지 간 의존성이 복잡함
4. 변환 시 위험이 너무 높음

**예상 일정**: 8-12주
**예상 비용**: $350,000 (초기) + $150,000/년 (운영)



### 시나리오 2: 중소 제조사 (복잡도 낮음)

**상황**:
- SQL 쿼리: 450개
- PL/SQL 오브젝트: 35개 (프로시저 25개, 함수 10개)
- 코드 라인 수: 8,500줄
- 평균 복잡도: 3.2 / 10

**분석 결과**:
```
복잡도 분포:
- 매우 복잡 (7-10점): 0%
- 복잡 (5-7점): 8%
- 중간 (3-5점): 35%
- 간단 (0-3점): 57%

감지된 Oracle 특화 기능:
- DECODE: 15개
- ROWNUM: 8개
- SYSDATE: 다수
- BULK 연산: 2개
```

**추천 전략**: **Refactor to Aurora MySQL**

**근거**:
1. 코드가 단순하고 개수가 적음
2. Oracle 특화 기능이 대부분 쉽게 변환 가능
3. PL/SQL을 애플리케이션으로 이관 가능
4. 장기적으로 비용 절감 효과 큼

**예상 일정**: 12-16주
**예상 비용**: $280,000 (초기) + $25,000/년 (운영)

**5년 TCO 비교**:
- Replatform: $350,000 + ($150,000 × 5) = $1,100,000
- MySQL: $280,000 + ($25,000 × 5) = $405,000
- **절감액: $695,000 (63% 절감)**



### 시나리오 3: 중견 유통사 (복잡도 중간)

**상황**:
- SQL 쿼리: 1,200개
- PL/SQL 오브젝트: 180개 (패키지 15개, 프로시저 120개, 함수 45개)
- 코드 라인 수: 35,000줄
- 평균 복잡도: 5.8 / 10
- BULK 연산: 45개

**분석 결과**:
```
복잡도 분포:
- 매우 복잡 (7-10점): 12%
- 복잡 (5-7점): 48%
- 중간 (3-5점): 30%
- 간단 (0-3점): 10%

감지된 Oracle 특화 기능:
- BULK COLLECT: 45개
- 분석 함수 (OVER): 85개
- DECODE: 120개
- 패키지 의존성: 60개
```

**추천 전략**: **Refactor to Aurora PostgreSQL**

**근거**:
1. 복잡도가 중간 수준으로 변환 가능
2. BULK 연산이 많아 MySQL은 부적합
3. PL/pgSQL로 70-75% 자동 변환 가능
4. 균형 잡힌 비용과 기능

**예상 일정**: 16-20주
**예상 비용**: $520,000 (초기) + $35,000/년 (운영)

**변환 전략**:
- BULK COLLECT → PostgreSQL ARRAY 사용
- 분석 함수 → PostgreSQL 네이티브 지원
- DECODE → CASE WHEN 변환
- 패키지 → 스키마로 구조화



---

## 💡 핵심 강점

### 1. 정량화된 복잡도 평가

**문제**: "이 코드가 얼마나 복잡한가?"라는 질문에 주관적으로만 답할 수 있었음

**해결**: 0-10점 척도로 객관적인 숫자 제공

```
예시:
- "이 쿼리는 복잡해 보여요" (주관적) 
  → "이 쿼리는 7.8점으로 매우 복잡합니다" (객관적)

- "변환하기 어려울 것 같아요" (추측)
  → "변환 난이도 8.5점, 완전 재설계 필요" (근거 있는 판단)
```

### 2. 타겟 DB별 최적화

**문제**: PostgreSQL과 MySQL은 다른 데이터베이스인데 같은 기준으로 평가

**해결**: 각 데이터베이스의 특성에 맞는 가중치 적용

```
예시: 서브쿼리 중첩 깊이 3단계

PostgreSQL 평가:
- 서브쿼리 지원 우수 → 2.0점 (중간)

MySQL 평가:
- 서브쿼리 최적화 약함 → 6.0점 (복잡)
```

### 3. 백분위수 기반 인스턴스 사이징

**문제**: 평균 CPU 사용률만 보고 인스턴스 선택 → 피크 시간에 성능 문제

**해결**: P99 백분위수 기준으로 안정적인 성능 보장

```
예시:
평균 CPU: 45% → db.r6i.xlarge 선택 (4 vCPU)
피크 CPU (P99): 78% → db.r6i.2xlarge 선택 (8 vCPU)

결과: 피크 시간에도 안정적인 성능 유지
```



### 4. 2차원 의사결정 매트릭스

**문제**: 복잡도만 보거나 개수만 보면 잘못된 판단

**해결**: 복잡도 × 개수를 동시에 고려

```
예시 1: 복잡도 높음 + 개수 적음
- 복잡도: 8.5점
- 개수: 20개
- 판단: PostgreSQL로 변환 가능 (신중하게)

예시 2: 복잡도 높음 + 개수 많음
- 복잡도: 8.5점
- 개수: 500개
- 판단: Replatform (변환 불가능)

예시 3: 복잡도 낮음 + 개수 많음
- 복잡도: 3.2점
- 개수: 500개
- 판단: PostgreSQL로 변환 (작업량 많지만 가능)
```

### 5. AI 도구 통합

**문제**: 수작업으로 코드 변환 시 시간과 비용이 너무 많이 듦

**해결**: AI 도구(Claude, ChatGPT 등) 활용으로 40% 시간 절감, 35% 비용 절감

```
전통적 방식:
- PL/SQL 1,000줄 변환
- 수작업: 20시간 소요
- 비용: $2,000

AI 도구 활용:
- AI가 초안 생성: 2시간
- 사람이 검토/수정: 10시간
- 총 12시간 (40% 절감)
- 비용: $1,300 (35% 절감)
```

### 6. 병렬 처리

**문제**: 수천 개 파일을 순차적으로 분석하면 너무 오래 걸림

**해결**: CPU 코어 수만큼 병렬 처리

```
예시: 3,000개 파일 분석

순차 처리:
- 파일당 2초
- 총 6,000초 (100분)

병렬 처리 (8 코어):
- 8개씩 동시 처리
- 총 750초 (12.5분)
- 8배 빠름
```



### 7. 자동 변환 가이드 제공

**문제**: Oracle 특화 기능을 어떻게 변환해야 할지 모름

**해결**: 감지된 기능별로 자동으로 변환 방법 제시

```
예시: CONNECT BY 감지

자동 생성된 가이드:
┌─────────────────────────────────────────────────┐
│ Oracle 기능: CONNECT BY (계층 쿼리)             │
├─────────────────────────────────────────────────┤
│ PostgreSQL 대체 방법:                           │
│ - WITH RECURSIVE 사용                           │
│ - 성능: 유사                                    │
│ - 난이도: 중간                                  │
│                                                 │
│ MySQL 대체 방법:                                │
│ - 애플리케이션 레벨에서 재귀 처리               │
│ - 성능: 느림                                    │
│ - 난이도: 높음                                  │
└─────────────────────────────────────────────────┘
```

### 8. Executive Summary

**문제**: 기술 담당자가 아닌 경영진에게 설명하기 어려움

**해결**: 비기술적 언어로 작성된 1페이지 요약 제공

```
Executive Summary 예시:

제목: Oracle 데이터베이스 AWS 마이그레이션 전략

추천 전략: Aurora PostgreSQL로 Refactor

핵심 요약:
현재 Oracle 데이터베이스를 Aurora PostgreSQL로 전환하는 것을 
추천합니다. 이 전략은 초기 투자 대비 장기적으로 가장 높은 
비용 절감 효과를 제공하며, 기술적 위험도 관리 가능한 수준입니다.

예상 기간: 16-20주
예상 비용: $850,000 (초기) + $50,000/년 (운영)

주요 이점:
✓ 5년간 $1.2M 비용 절감 (Oracle 대비)
✓ 클라우드 네이티브 기능 활용
✓ 자동 백업 및 고가용성
✓ 오픈소스 기반으로 벤더 종속성 제거

주요 위험:
⚠ PL/SQL 변환 작업 필요 (180개 오브젝트)
⚠ 일부 성능 차이 발생 가능 (BULK 연산)
⚠ 팀 교육 필요 (PostgreSQL 학습)

완화 방안:
→ AI 도구 활용으로 변환 시간 40% 단축
→ 성능 테스트 및 최적화 단계 포함
→ 단계별 교육 프로그램 제공
```



---

## 🚀 누가 사용하나?

### 1. 클라우드 아키텍트

**사용 목적**: 마이그레이션 전략 수립

**활용 방법**:
- 코드 복잡도 분석으로 기술적 실현 가능성 평가
- 성능 메트릭으로 인스턴스 사이징
- 3가지 전략 중 최적안 선택

**효과**:
- 전략 수립 시간 80% 단축 (수주 → 수일)
- 객관적 근거 기반 의사결정
- 위험 요소 사전 식별

### 2. 데이터베이스 관리자 (DBA)

**사용 목적**: 기술적 난이도 평가

**활용 방법**:
- SQL/PL-SQL 복잡도 분석
- Oracle 특화 기능 식별
- 변환 가이드 참고

**효과**:
- 수작업 코드 리뷰 불필요
- 변환 어려운 코드 우선순위 파악
- 변환 방법 자동 제시

### 3. 프로젝트 매니저 (PM)

**사용 목적**: 일정 및 예산 수립

**활용 방법**:
- 예상 기간 및 비용 확인
- 단계별 로드맵 참고
- Executive Summary로 경영진 보고

**효과**:
- 정확한 견적 산출
- 현실적인 일정 수립
- 경영진 설득 자료 확보

### 4. 개발팀 리더

**사용 목적**: 기술 스택 전환 계획

**활용 방법**:
- 애플리케이션 코드 변경 범위 파악
- 팀 교육 계획 수립
- 위험 요소 대응 방안 마련

**효과**:
- 팀 역량 평가
- 교육 계획 수립
- 리소스 배분 최적화



---

## 📈 기대 효과

### 시간 절감

**전통적 방식**:
```
1. 수작업 코드 리뷰: 4-8주
2. 성능 분석: 2-4주
3. 전략 수립: 2-3주
4. 견적 산출: 1-2주
───────────────────────
총 9-17주 소요
```

**Oracle Migration Analyzer 사용**:
```
1. 코드 복잡도 분석: 10분
2. 성능 메트릭 분석: 5분
3. 전략 추천: 5분
4. 리포트 생성: 즉시
───────────────────────
총 20분 소요 (99% 단축)
```

### 비용 절감

**분석 단계 비용 절감**:
- 전통적 방식: $50,000-$100,000 (컨설팅 비용)
- 자동화 도구: $0 (오픈소스)
- **절감액: $50,000-$100,000**

**마이그레이션 비용 절감** (AI 도구 활용):
- 전통적 방식: $1,500,000
- AI 도구 활용: $975,000 (35% 절감)
- **절감액: $525,000**

**운영 비용 절감** (5년 기준):
- Oracle 라이선스: $750,000
- Aurora PostgreSQL: $250,000
- **절감액: $500,000**

**총 절감액: $1,025,000-$1,125,000**



### 위험 감소

**전통적 방식의 위험**:
- ❌ 주관적 판단으로 잘못된 전략 선택
- ❌ 숨겨진 복잡도 발견 못함
- ❌ 예상치 못한 비용 증가
- ❌ 일정 지연

**자동화 도구 사용 시**:
- ✅ 객관적 데이터 기반 의사결정
- ✅ 모든 코드 자동 분석
- ✅ 정확한 비용 예측
- ✅ 현실적인 일정 수립

### 품질 향상

**전통적 방식**:
- 샘플링 분석 (전체의 10-20%)
- 사람의 실수 가능성
- 일관성 부족

**자동화 도구**:
- 전수 조사 (100%)
- 일관된 기준 적용
- 재현 가능한 결과

---

## 🎓 학습 곡선

### 초급 사용자 (5분)

**목표**: 기본 분석 실행

```bash
# 1. 설치
pip install -r requirements.txt

# 2. 코드 분석
oracle-complexity-analyzer -d /path/to/sql -o markdown

# 3. 결과 확인
cat reports/sql_complexity_PGSQL.md
```

**필요 지식**: 기본 CLI 명령어

### 중급 사용자 (30분)

**목표**: 전체 워크플로우 실행

```bash
# 1. 코드 복잡도 분석
oracle-complexity-analyzer -d sample_data -t postgresql -o markdown

# 2. 성능 메트릭 분석
dbcsi-analyzer --file awr_report.out --format markdown

# 3. 마이그레이션 추천
migration-recommend --reports-dir reports/sample_data
```

**필요 지식**: 
- Oracle 데이터베이스 기본 개념
- AWR/Statspack 리포트 이해

### 고급 사용자 (2시간)

**목표**: 커스터마이징 및 통합

```python
# Python API 사용
from src.oracle_complexity_analyzer import OracleComplexityAnalyzer
from src.dbcsi.parser import AWRParser

# 분석기 생성
analyzer = OracleComplexityAnalyzer(target_database="postgresql")

# 코드 분석
result = analyzer.analyze_file("query.sql")

# 결과 활용
if result.normalized_score > 7.0:
    print("복잡도 높음: 전문가 검토 필요")
```

**필요 지식**:
- Python 프로그래밍
- 데이터 모델 이해
- 커스터마이징 요구사항



---

## ❓ 자주 묻는 질문 (FAQ)

### Q1. 분석 결과가 100% 정확한가요?

**A**: 95% 이상의 정확도를 목표로 하지만, 다음 사항을 고려해야 합니다:

- ✅ **정확한 부분**: 코드 구조, Oracle 기능 감지, 복잡도 점수
- ⚠️ **주의 필요**: 비즈니스 로직의 의미, 성능 최적화 여부
- 💡 **권장**: 자동 분석 결과를 기반으로 전문가가 최종 검토

### Q2. 어떤 Oracle 버전을 지원하나요?

**A**: Oracle 10g 이상 모든 버전 지원

- Oracle 10g, 11g, 12c, 18c, 19c, 21c
- AWR과 Statspack 모두 지원
- Enterprise Edition과 Standard Edition 모두 분석 가능

### Q3. 분석에 얼마나 시간이 걸리나요?

**A**: 코드 양에 따라 다르지만 매우 빠릅니다:

```
소규모 (100개 파일): 1-2분
중규모 (1,000개 파일): 5-10분
대규모 (10,000개 파일): 30-60분
```

병렬 처리로 CPU 코어 수만큼 빠르게 처리됩니다.

### Q4. 실제 마이그레이션도 해주나요?

**A**: 아니요, 이 도구는 **분석 및 추천**만 제공합니다:

- ✅ 제공: 복잡도 분석, 전략 추천, 변환 가이드
- ❌ 미제공: 실제 코드 변환, 데이터 마이그레이션

실제 마이그레이션은 AWS DMS, SCT 등의 도구나 전문 컨설팅이 필요합니다.

### Q5. 비용이 얼마나 드나요?

**A**: 오픈소스로 **무료**입니다:

- MIT 라이선스
- 상업적 사용 가능
- 수정 및 재배포 가능

### Q6. 다른 클라우드(Azure, GCP)도 지원하나요?

**A**: 현재는 AWS만 지원하지만, 확장 가능합니다:

- ✅ 현재: AWS (RDS, Aurora)
- 🔜 계획: Azure SQL Database, Google Cloud SQL
- 💡 기여: 오픈소스이므로 누구나 기여 가능



### Q7. 보안은 어떻게 되나요?

**A**: 로컬에서 실행되므로 안전합니다:

- ✅ 모든 분석이 로컬 환경에서 실행
- ✅ 외부 서버로 데이터 전송 없음
- ✅ 민감한 정보 노출 위험 없음
- ✅ 오픈소스로 코드 검증 가능

### Q8. 기존 도구(AWS SCT)와 차이점은?

**A**: 상호 보완적인 도구입니다:

| 기능 | Oracle Migration Analyzer | AWS SCT |
|------|---------------------------|---------|
| 복잡도 점수화 | ✅ 0-10점 척도 | ❌ 없음 |
| 전략 추천 | ✅ 3가지 전략 | ❌ 없음 |
| 코드 변환 | ❌ 가이드만 제공 | ✅ 자동 변환 |
| 데이터 마이그레이션 | ❌ 미지원 | ✅ 지원 |
| 사용 시점 | 계획 단계 | 실행 단계 |

**권장 워크플로우**:
1. Oracle Migration Analyzer로 전략 수립
2. AWS SCT로 실제 변환 및 마이그레이션

### Q9. Python을 모르는데 사용할 수 있나요?

**A**: 네, CLI만 사용하면 됩니다:

```bash
# Python 코드 작성 불필요
# 명령어만 실행하면 됨
oracle-complexity-analyzer -d /path/to/files -o markdown
```

Python API는 고급 사용자나 자동화가 필요한 경우에만 사용합니다.

### Q10. 결과를 다른 사람과 공유하려면?

**A**: Markdown 또는 JSON 형식으로 저장됩니다:

```bash
# Markdown 리포트 생성 (읽기 쉬움)
oracle-complexity-analyzer -d /path -o markdown

# JSON 리포트 생성 (프로그래밍 활용)
oracle-complexity-analyzer -d /path -o json

# 둘 다 생성
oracle-complexity-analyzer -d /path -o both
```

생성된 파일을 이메일, Slack, Confluence 등으로 공유하면 됩니다.

---

## 🔮 향후 계획

### 단기 (3개월)

- [ ] 웹 UI 제공 (CLI 대신 브라우저에서 사용)
- [ ] 더 많은 Oracle 기능 지원
- [ ] 성능 최적화 (더 빠른 분석)
- [ ] 다국어 지원 (영어, 한국어, 일본어)

### 중기 (6개월)

- [ ] Azure SQL Database 지원
- [ ] Google Cloud SQL 지원
- [ ] 실시간 협업 기능
- [ ] 대시보드 및 시각화

### 장기 (1년)

- [ ] AI 기반 자동 코드 변환
- [ ] 마이그레이션 시뮬레이션
- [ ] 비용 최적화 추천
- [ ] 커뮤니티 플랫폼



---

## 🎬 시작하기

### 빠른 시작 (5분)

```bash
# 1. 저장소 클론
git clone <repository-url>
cd oracle-migration-analyzer

# 2. 의존성 설치
pip install -r requirements.txt

# 3. 샘플 데이터로 테스트
oracle-complexity-analyzer -d sample_code -o markdown

# 4. 결과 확인
cat reports/sample_code/PGSQL/sql_complexity_PGSQL.md
```

### 실제 프로젝트 적용

```bash
# 1. SQL/PL-SQL 파일 준비
# - 폴더에 .sql, .pls 파일 모음

# 2. AWR/Statspack 리포트 준비 (선택사항)
# - .out 파일 준비

# 3. 분석 실행
oracle-complexity-analyzer -d /path/to/sql -t postgresql -o markdown
dbcsi-analyzer --file awr_report.out --format markdown
migration-recommend --reports-dir reports/

# 4. 리포트 확인
# reports/ 폴더에 생성된 Markdown 파일 확인
```

### 도움말

```bash
# 각 도구의 상세 옵션 확인
oracle-complexity-analyzer --help
dbcsi-analyzer --help
migration-recommend --help
```

---

## 📚 더 알아보기

### 문서

- [README.md](../README.md) - 전체 개요
- [SQL 복잡도 계산 공식](SQL_COMPLEXITY_FORMULA_EXPLAINED.md) - SQL 쿼리 복잡도 분석
- [PL/SQL 복잡도 계산 공식](PLSQL_COMPLEXITY_FORMULA_EXPLAINED.md) - PL/SQL 오브젝트 복잡도 분석
- [SQL 복잡도 점수 개선 방안](SQL_COMPLEXITY_SCORE_IMPROVEMENT.md) - 점수 기준 개선 제안
- [PL/SQL 복잡도 점수 개선 방안](PLSQL_COMPLEXITY_SCORE_IMPROVEMENT.md) - 점수 기준 개선 제안
- [마이그레이션 추천 임계값 개선 방안](THRESHOLD_IMPROVEMENT_PROPOSAL.md) - 의사결정 임계값 분석

### 예제

- `sample_code/` - 샘플 SQL/PL-SQL 파일
- `reports/sample_code/` - 샘플 분석 결과
- `example_cli_usage.sh` - CLI 사용 예제

### 커뮤니티

- GitHub Issues - 버그 리포트 및 기능 요청
- GitHub Discussions - 질문 및 토론
- Pull Requests - 기여 환영

---

## 🏆 결론

**Oracle Migration Analyzer는 Oracle 데이터베이스의 AWS 클라우드 마이그레이션을 계획할 때 반드시 필요한 도구입니다.**

### 핵심 가치

1. **시간 절약**: 수주 → 수분 (99% 단축)
2. **비용 절감**: $1M+ 절감 가능
3. **위험 감소**: 객관적 데이터 기반 의사결정
4. **품질 향상**: 전수 조사 및 일관된 기준

### 고복잡도 임계값

| 타겟 DB | 임계값 | 의미 |
|---------|--------|------|
| PostgreSQL | **5.0점** | 이 점수 이상이면 "복잡" 판정 |
| MySQL | **7.0점** | 이 점수 이상이면 "복잡" 판정 |

### 누구에게 필요한가?

- ✅ Oracle을 AWS로 옮기려는 모든 조직
- ✅ 마이그레이션 전략을 수립하는 아키텍트
- ✅ 기술적 난이도를 평가하는 DBA
- ✅ 일정과 예산을 수립하는 PM
- ✅ 경영진을 설득해야 하는 리더

### 시작하세요

```bash
# 지금 바로 시작하세요!
git clone <repository-url>
cd oracle-migration-analyzer
pip install -r requirements.txt
oracle-complexity-analyzer -d sample_code -o markdown
```

**Oracle 마이그레이션, 이제 더 이상 두렵지 않습니다.** 🚀

---

> **문서 이력**
> - 2026-01-29: 최신 코드 기반 업데이트 (고복잡도 임계값 추가)
> - 2026-01-28: 초안 작성
> - 대상 독자: 마이그레이션 담당자, DBA, 개발자, PM, 경영진

